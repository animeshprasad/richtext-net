{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sichenglei/Desktop/kaggle/salt/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "\n",
      "Bad key \"ckend\" on line 1 in\n",
      "/Users/sichenglei/.matplotlib/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "/Users/sichenglei/Desktop/kaggle/salt/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from data_reader import *\n",
    "from evaluate_new import *\n",
    "from sklearn_crfsuite import CRF \n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "## Get the doc level test data\n",
    "doc_dir = \"../../data_doc/\"\n",
    "def get_doc_test(labels=\"golden_data\", text=\"test_file\"):\n",
    "    test_labels = []\n",
    "    test_doc = []\n",
    "    with open(doc_dir+labels, 'r') as doc_labels, open(doc_dir+text, 'r') as doc_text:\n",
    "        d_labels = doc_labels.readlines()\n",
    "        d_text = doc_text.readlines()\n",
    "        assert len(d_labels) == len(d_text), \"Mismatch\"\n",
    "        for i in range(len(d_labels)):\n",
    "            test_labels.append(d_labels[i].strip())\n",
    "            \n",
    "            text = d_text[i].strip()\n",
    "            text = re.sub('\\d', '0', text)\n",
    "            text = re.sub('[^ ]- ', '', text)\n",
    "            \n",
    "            test_doc.append(text)\n",
    "    return test_labels, test_doc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_test_y, doc_test_x = get_doc_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(doc, labels):\n",
    "    doc = doc.strip().split()\n",
    "    labels = labels.strip().split('|')\n",
    "    labels = [la.split() for la in labels]\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            labels[i][j] = int(labels[i][j])\n",
    "\n",
    "    res_labels = [0]*len(doc)\n",
    "    for la in labels:\n",
    "        if la[2]!=0:\n",
    "            start = la[0]\n",
    "            end = la[1]\n",
    "            res_labels[start : end+1] = [1]*(end+1-start)\n",
    "    return [(doc[i], str(res_labels[i])) for i in range(len(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script implements a purely feature based CRF.\n",
    "train_sents = get_sents(\"../../data_30_0.1%neg/train.txt\")\n",
    "val_sents = get_sents(\"../../data_30_0.1%neg/validate.txt\")\n",
    "test_sents = get_sents(\"../../data_30_0.1%neg/test.txt\")\n",
    "\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    ##youmay add more features\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "##CRF takes string as labels\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n",
    "\n",
    "##labels are strings\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "Y_train = [sent2labels(s) for s in train_sents]\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "Y_test = [sent2labels(s) for s in test_sents]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tests = [read_doc(doc_test_x[d], doc_test_y[d]) for d in range(len(doc_test_x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_doc_test = [sent2features(s) for s in doc_tests]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict one doc\n",
    "def doc_pred(model, doc, MAXLEN):\n",
    "    splits = []\n",
    "    for i in range(0, len(doc), MAXLEN):\n",
    "        splits.append(doc[i : i+MAXLEN])\n",
    "    preds = model.predict(splits)\n",
    "    preds = [p for pd in preds for p in pd]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=False, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "crf.fit(X_train, Y_train)\n",
    "\n",
    "# labels = list(crf.classes_)\n",
    "# y_pred = crf.predict(X_test)\n",
    "# ##average F1\n",
    "# # metrics.flat_f1_score(Y_test, y_pred,\n",
    "# #                       average='weighted', labels=labels)\n",
    "\n",
    "# sorted_labels = sorted(\n",
    "#     labels,\n",
    "#     key=lambda name: (name[1:], name[0])\n",
    "# )\n",
    "# print(metrics.flat_classification_report(\n",
    "#     Y_test, y_pred, labels=sorted_labels, digits=3\n",
    "# ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "preds = [[int(a) for a in x] for x in y_pred]\n",
    "##record the prediceted start and end index\n",
    "with open('../../outputs/CRF_preds', 'w') as fout:\n",
    "    with open('../../data/test.txt', 'r') as test:\n",
    "        test_list = test.readlines()\n",
    "        for i in range(len(preds)):\n",
    "            sent = test_list[i].strip().split()\n",
    "            data_id = int(sent[2])\n",
    "            pub_id = int(sent[3])\n",
    "\n",
    "            first = 0\n",
    "            j = 0\n",
    "            string = ''\n",
    "            no_mention = True\n",
    "            while j<len(preds[i]):\n",
    "                while j<len(preds[i]) and preds[i][j]== 0:\n",
    "                    j+=1\n",
    "                if j<len(preds[i]) and preds[i][j] == 1:\n",
    "                    no_mention=False\n",
    "                    start = j\n",
    "                    while j+1<len(preds[i]) and preds[i][j+1]==1:\n",
    "                        j+=1\n",
    "                    end = j \n",
    "                    if first > 0:\n",
    "                        string += \" | \"\n",
    "                    string += (str(start)+' '+str(end)+' '+str(data_id)+' '+str(pub_id))\n",
    "                    j+=1\n",
    "                    first += 1\n",
    "            if no_mention:\n",
    "                fout.write(\"0 0 0 \"+str(pub_id)+'\\n')\n",
    "            else:\n",
    "                fout.write(string+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doc level pred\n",
    "doc_preds = [doc_pred(crf, d, 30) for d in X_doc_test]\n",
    "doc_preds = [[int(a) for a in x] for x in doc_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## record the prediceted start and end index\n",
    "## for doc level\n",
    "## write all start and end indices (0 0 if not mention)\n",
    "with open('../../doc_outputs/CRF_preds', 'w') as fout:\n",
    "    for i in range(len(doc_preds)):\n",
    "        first = 0\n",
    "        j = 0\n",
    "        string = ''\n",
    "        no_mention = True\n",
    "        while j<len(doc_preds[i]):\n",
    "            while j<len(doc_preds[i]) and doc_preds[i][j]== 0:\n",
    "                j+=1\n",
    "            if j<len(doc_preds[i]) and doc_preds[i][j] == 1:\n",
    "                no_mention=False\n",
    "                start = j\n",
    "                while j+1<len(doc_preds[i]) and doc_preds[i][j+1]==1:\n",
    "                    j+=1\n",
    "                end = j \n",
    "                if first > 0:\n",
    "                    string += \" | \"\n",
    "                string += (str(start)+' '+str(end))\n",
    "                j+=1\n",
    "                first += 1\n",
    "        if no_mention:\n",
    "            fout.write(\"0 0\"'\\n')\n",
    "        else:\n",
    "            fout.write(string+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017406440382941688\n"
     ]
    }
   ],
   "source": [
    "print (doc_exact_match('../../doc_outputs/CRF_preds', '../../data_doc/golden_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034812880765883376\n"
     ]
    }
   ],
   "source": [
    "print (doc_partial_match('../../doc_outputs/CRF_preds', '../../data_doc/golden_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583873290136789\n"
     ]
    }
   ],
   "source": [
    "print (discovery_exact_match('../../outputs/CRF_preds', '../../data/test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7930409568684306\n"
     ]
    }
   ],
   "source": [
    "print (discovery_partial_match('../../outputs/CRF_preds', '../../data/test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from data_reader import *\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import metrics \n",
    "from keras_contrib.layers import CRF\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12785/18096 words covered in glove\n",
      "Train on 24094 samples, validate on 3347 samples\n",
      "Epoch 1/10\n",
      "24094/24094 [==============================] - 36s 1ms/step - loss: 0.2253 - acc: 0.9127 - val_loss: 0.1625 - val_acc: 0.9344\n",
      "Epoch 2/10\n",
      "24094/24094 [==============================] - 33s 1ms/step - loss: 0.1538 - acc: 0.9396 - val_loss: 0.1368 - val_acc: 0.9461\n",
      "Epoch 3/10\n",
      "24094/24094 [==============================] - 34s 1ms/step - loss: 0.1339 - acc: 0.9474 - val_loss: 0.1239 - val_acc: 0.9511\n",
      "Epoch 4/10\n",
      "24094/24094 [==============================] - 34s 1ms/step - loss: 0.1226 - acc: 0.9518 - val_loss: 0.1140 - val_acc: 0.9547\n",
      "Epoch 5/10\n",
      "24094/24094 [==============================] - 33s 1ms/step - loss: 0.1143 - acc: 0.9551 - val_loss: 0.1066 - val_acc: 0.9580\n",
      "Epoch 6/10\n",
      "24094/24094 [==============================] - 33s 1ms/step - loss: 0.1078 - acc: 0.9573 - val_loss: 0.1069 - val_acc: 0.9569\n"
     ]
    }
   ],
   "source": [
    "# BLSTM\n",
    "def sent2features(sent):\n",
    "\treturn [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "\treturn [int(label) for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "\treturn [token for token, label in sent]\n",
    "\n",
    "X_train = [sent2tokens(s) for s in train_sents]\n",
    "Y_train = [sent2labels(s) for s in train_sents]\n",
    "X_val = [sent2tokens(s) for s in val_sents]\n",
    "Y_val = [sent2labels(s) for s in val_sents]\n",
    "X_test = [sent2tokens(s) for s in test_sents]\n",
    "Y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "\n",
    "# ##load glove\n",
    "embedding_index = {}\n",
    "f = open('../glove.6B.50d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembedding_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train+X_val+X_test)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "##hyperparameters\n",
    "vocab_size = len(word_index)+1\n",
    "maxlen = 30\n",
    "emb_dim = 50\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "counter = 0\n",
    "for word, i in word_index.items():\n",
    "\tembedding_vector = embedding_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "\t\tcounter += 1\n",
    "\telse:\n",
    "\t\tembedding_matrix[i] = np.random.randn(emb_dim)\n",
    "print (\"{}/{} words covered in glove\".format(counter, vocab_size))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_val = np.asarray(Y_val)\n",
    "Y_test = np.asarray(Y_test)\n",
    "\n",
    "#labels need to be 3D\n",
    "Y_train = np.expand_dims(Y_train, axis=2)\n",
    "Y_val = np.expand_dims(Y_val, axis=2)\n",
    "Y_test = np.expand_dims(Y_test, axis=2)\n",
    "\n",
    "##build model\n",
    "input = Input(shape=(maxlen,))\n",
    "model = Embedding(vocab_size, emb_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(1, activation='sigmoid'))(model)\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "earlyStop = [EarlyStopping(monitor='val_loss', patience=1)]\n",
    "history = model.fit(X_train, Y_train, batch_size=64, epochs=10, validation_data=(X_val, Y_val), \n",
    "\tcallbacks=earlyStop) \n",
    "\n",
    "\n",
    "# preds = model.predict(X_test)\n",
    "# test = [[1 if y>=0.5 else 0 for y in x] for x in preds]\n",
    "# test_arr = np.asarray(test)\n",
    "# test = np.reshape(test_arr, (-1))\n",
    "# target = np.reshape(Y_test, (-1))\n",
    "\n",
    "# print (metrics.precision_recall_fscore_support(target, test, average=None,\n",
    "#                                               labels=[0, 1]))\n",
    "\n",
    "\n",
    "# preds = test_arr\n",
    "# ##record the prediceted start and end index\n",
    "# with open('../../outputs/BiLSTM_preds', 'w') as fout:\n",
    "# \twith open('../../data/test.txt', 'r') as test:\n",
    "# \t\ttest_list = test.readlines()\n",
    "# \t\tfor i in range(len(preds)):\n",
    "# \t\t\tsent = test_list[i].strip().split()\n",
    "# \t\t\tdata_id = int(sent[2])\n",
    "# \t\t\tpub_id = int(sent[3])\n",
    "\n",
    "# \t\t\tfirst = 0\n",
    "# \t\t\tj = 0\n",
    "# \t\t\tstring = ''\n",
    "# \t\t\tno_mention = True\n",
    "# \t\t\twhile j<len(preds[i]):\n",
    "# \t\t\t\twhile j<len(preds[i]) and preds[i][j]== 0:\n",
    "# \t\t\t\t\tj+=1\n",
    "# \t\t\t\tif j<len(preds[i]) and preds[i][j] == 1:\n",
    "# \t\t\t\t\tno_mention=False\n",
    "# \t\t\t\t\tstart = j\n",
    "# \t\t\t\t\twhile j+1<len(preds[i]) and preds[i][j+1]==1:\n",
    "# \t\t\t\t\t\tj+=1\n",
    "# \t\t\t\t\tend = j \n",
    "# \t\t\t\t\tif first > 0:\n",
    "# \t\t\t\t\t\tstring += \" | \"\n",
    "# \t\t\t\t\tstring += (str(start)+' '+str(end)+' '+str(data_id)+' '+str(pub_id))\n",
    "# \t\t\t\t\tj+=1\n",
    "# \t\t\t\t\tfirst += 1\n",
    "# \t\t\tif no_mention:\n",
    "# \t\t\t\tfout.write(\"0 0 0 \"+str(pub_id)+'\\n')\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tfout.write(string+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713324360699865\n",
      "0.8089459084604715\n"
     ]
    }
   ],
   "source": [
    "print (discovery_exact_match('../../outputs/BiLSTM_preds', '../../data/test.txt'))\n",
    "print (discovery_partial_match('../../outputs/BiLSTM_preds', '../../data/test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_doc_test = [sent2tokens(s) for s in doc_tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict one doc\n",
    "def doc_pred(model, doc, MAXLEN):\n",
    "    splits = []\n",
    "    for i in range(0, len(doc), MAXLEN):\n",
    "        splits.append(doc[i : i+MAXLEN])\n",
    "    splits = tokenizer.texts_to_sequences(splits)\n",
    "    splits = pad_sequences(splits, maxlen=MAXLEN)\n",
    "    preds = model.predict(splits)\n",
    "    \n",
    "    preds = [1 if p>=0.5 else 0 for pd in preds for p in pd]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_preds = [doc_pred(model, d, 30) for d in X_doc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../doc_outputs/BiLSTM_preds', 'w') as fout:\n",
    "    for i in range(len(doc_preds)):\n",
    "        first = 0\n",
    "        j = 0\n",
    "        string = ''\n",
    "        no_mention = True\n",
    "        while j<len(doc_preds[i]):\n",
    "            while j<len(doc_preds[i]) and doc_preds[i][j]== 0:\n",
    "                j+=1\n",
    "            if j<len(doc_preds[i]) and doc_preds[i][j] == 1:\n",
    "                no_mention=False\n",
    "                start = j\n",
    "                while j+1<len(doc_preds[i]) and doc_preds[i][j+1]==1:\n",
    "                    j+=1\n",
    "                end = j \n",
    "                if first > 0:\n",
    "                    string += \" | \"\n",
    "                string += (str(start)+' '+str(end))\n",
    "                j+=1\n",
    "                first += 1\n",
    "        if no_mention:\n",
    "            fout.write(\"0 0\"'\\n')\n",
    "        else:\n",
    "            fout.write(string+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003898635477582846\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print (doc_partial_match('../../doc_outputs/BiLSTM_preds', '../../data_doc/golden_data'))\n",
    "print (doc_exact_match('../../doc_outputs/BiLSTM_preds', '../../data_doc/golden_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12785/18096 words covered in glove\n",
      "Train on 24094 samples, validate on 3347 samples\n",
      "Epoch 1/10\n",
      "24094/24094 [==============================] - 43s 2ms/step - loss: 0.1476 - acc: 0.9049 - val_loss: 0.0908 - val_acc: 0.9352\n",
      "Epoch 2/10\n",
      "24094/24094 [==============================] - 39s 2ms/step - loss: 0.0777 - acc: 0.9429 - val_loss: 0.0608 - val_acc: 0.9497\n",
      "Epoch 3/10\n",
      "24094/24094 [==============================] - 41s 2ms/step - loss: 0.0556 - acc: 0.9508 - val_loss: 0.0434 - val_acc: 0.9545\n",
      "Epoch 4/10\n",
      "24094/24094 [==============================] - 40s 2ms/step - loss: 0.0388 - acc: 0.9556 - val_loss: 0.0287 - val_acc: 0.9566\n",
      "Epoch 5/10\n",
      "24094/24094 [==============================] - 43s 2ms/step - loss: 0.0238 - acc: 0.9583 - val_loss: 0.0162 - val_acc: 0.9600\n",
      "Epoch 6/10\n",
      "24094/24094 [==============================] - 42s 2ms/step - loss: 0.0098 - acc: 0.9602 - val_loss: 0.0013 - val_acc: 0.9616\n",
      "Epoch 7/10\n",
      "24094/24094 [==============================] - 36s 1ms/step - loss: -0.0042 - acc: 0.9622 - val_loss: -0.0118 - val_acc: 0.9615\n",
      "Epoch 8/10\n",
      "24094/24094 [==============================] - 40s 2ms/step - loss: -0.0179 - acc: 0.9633 - val_loss: -0.0244 - val_acc: 0.9632\n",
      "Epoch 9/10\n",
      "24094/24094 [==============================] - 41s 2ms/step - loss: -0.0312 - acc: 0.9639 - val_loss: -0.0379 - val_acc: 0.9638\n",
      "Epoch 10/10\n",
      "24094/24094 [==============================] - 45s 2ms/step - loss: -0.0451 - acc: 0.9655 - val_loss: -0.0495 - val_acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "#This script implements a BiLSTM-CRF model\n",
    "train_sents = get_sents(\"../../data_30_0.1%neg/train.txt\")\n",
    "val_sents = get_sents(\"../../data_30_0.1%neg/validate.txt\")\n",
    "test_sents = get_sents(\"../../data_30_0.1%neg/test.txt\")\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "\treturn [int(label) for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "\treturn [token for token, label in sent]\n",
    "\n",
    "X_train = [sent2tokens(s) for s in train_sents]\n",
    "Y_train = [sent2labels(s) for s in train_sents]\n",
    "X_val = [sent2tokens(s) for s in val_sents]\n",
    "Y_val = [sent2labels(s) for s in val_sents]\n",
    "X_test = [sent2tokens(s) for s in test_sents]\n",
    "Y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "\n",
    "##load glove\n",
    "embedding_index = {}\n",
    "f = open('../glove.6B.50d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembedding_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train+X_val+X_test)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "##hyperparameters\n",
    "vocab_size = len(word_index)+1\n",
    "maxlen = 30\n",
    "emb_dim = 50\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "counter = 0\n",
    "for word, i in word_index.items():\n",
    "\tembedding_vector = embedding_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "\t\tcounter += 1\n",
    "\telse:\n",
    "\t\tembedding_matrix[i] = np.random.randn(emb_dim)\n",
    "print (\"{}/{} words covered in glove\".format(counter, vocab_size))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_val = np.asarray(Y_val)\n",
    "Y_test = np.asarray(Y_test)\n",
    "\n",
    "#labels need to be 3D\n",
    "Y_train = np.expand_dims(Y_train, axis=2)\n",
    "Y_val = np.expand_dims(Y_val, axis=2)\n",
    "Y_test = np.expand_dims(Y_test, axis=2)\n",
    "\n",
    "##build model\n",
    "input = Input(shape=(maxlen,))\n",
    "model = Embedding(vocab_size, emb_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False)(input)\n",
    "model = Bidirectional(LSTM(100, return_sequences=True, recurrent_dropout=0.2))(model)\n",
    "model = TimeDistributed(Dense(50, activation='relu'))(model)\n",
    "model = TimeDistributed(Dropout(0.2))(model)\n",
    "##use CRF instead of Dense\n",
    "crf = CRF(2)\n",
    "out = crf(model)\n",
    "\n",
    "model = Model(input, out)\n",
    "\n",
    "\n",
    "Y_train_2 = keras.utils.to_categorical(Y_train)\n",
    "Y_val_2 = keras.utils.to_categorical(Y_val)\n",
    "Y_test_2 = keras.utils.to_categorical(Y_test)\n",
    "\n",
    "model.compile(optimizer='adam', loss=crf.loss_function, metrics=[crf.accuracy]) \n",
    "earlyStop = [EarlyStopping(monitor='val_loss', patience=1)]\n",
    "history = model.fit(X_train, Y_train_2, batch_size=64, epochs=10, \n",
    "                   validation_data=(X_val, Y_val_2), callbacks=earlyStop)\n",
    "\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "test = [[np.argmax(y) for y in x] for x in preds]\n",
    "test_arr = np.asarray(test)\n",
    "test = np.reshape(test_arr, (-1))\n",
    "\n",
    "# print (metrics.precision_recall_fscore_support(np.reshape(Y_test,(-1)), test, average=None,\n",
    "#                                               labels=[0, 1]))\n",
    "\n",
    "\n",
    "# preds = test_arr\n",
    "# ##record the prediceted start and end index\n",
    "# with open('../../outputs/BiLSTM_CRF_preds', 'w') as fout:\n",
    "# \twith open('../../data/test.txt', 'r') as test:\n",
    "# \t\ttest_list = test.readlines()\n",
    "# \t\tfor i in range(len(preds)):\n",
    "# \t\t\tsent = test_list[i].strip().split()\n",
    "# \t\t\tdata_id = int(sent[2])\n",
    "# \t\t\tpub_id = int(sent[3])\n",
    "\n",
    "# \t\t\tfirst = 0\n",
    "# \t\t\tj = 0\n",
    "# \t\t\tstring = ''\n",
    "# \t\t\tno_mention = True\n",
    "# \t\t\twhile j<len(preds[i]):\n",
    "# \t\t\t\twhile j<len(preds[i]) and preds[i][j]== 0:\n",
    "# \t\t\t\t\tj+=1\n",
    "# \t\t\t\tif j<len(preds[i]) and preds[i][j] == 1:\n",
    "# \t\t\t\t\tno_mention=False\n",
    "# \t\t\t\t\tstart = j\n",
    "# \t\t\t\t\twhile j+1<len(preds[i]) and preds[i][j+1]==1:\n",
    "# \t\t\t\t\t\tj+=1\n",
    "# \t\t\t\t\tend = j \n",
    "# \t\t\t\t\tif first > 0:\n",
    "# \t\t\t\t\t\tstring += \" | \"\n",
    "# \t\t\t\t\tstring += (str(start)+' '+str(end)+' '+str(data_id)+' '+str(pub_id))\n",
    "# \t\t\t\t\tj+=1\n",
    "# \t\t\t\t\tfirst += 1\n",
    "# \t\t\tif no_mention:\n",
    "# \t\t\t\tfout.write(\"0 0 0 \"+str(pub_id)+'\\n')\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tfout.write(string+'\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.98683506, 0.8217574 ]), array([0.97159827, 0.90992774]), array([0.9791574 , 0.86359793]), array([70207, 10103]))\n"
     ]
    }
   ],
   "source": [
    "print (metrics.precision_recall_fscore_support(np.reshape(Y_test,(-1)), test, average=None,\n",
    "                                              labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 183 arrays: [array([[{'bias': 1.0, 'word.lower()': 'copyright', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': '0000', '+1:word.istitle()': False, '+1:wo...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cb001354f262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_doc_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-cb001354f262>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_doc_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-2ffa4a333f61>\u001b[0m in \u001b[0;36mdoc_pred\u001b[0;34m(model, doc, MAXLEN)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXLEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msplits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mMAXLEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 183 arrays: [array([[{'bias': 1.0, 'word.lower()': 'copyright', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'BOS': True, '+1:word.lower()': '0000', '+1:word.istitle()': False, '+1:wo..."
     ]
    }
   ],
   "source": [
    "doc_preds = [doc_pred(model, d, 30) for d in X_doc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test_arr\n",
    "##record the prediceted start and end index\n",
    "with open('../../doc_outputs/BiLSTM_CRF_preds', 'w') as fout:\n",
    "\twith open('../../data/test.txt', 'r') as test:\n",
    "\t\ttest_list = test.readlines()\n",
    "\t\tfor i in range(len(preds)):\n",
    "\t\t\tsent = test_list[i].strip().split()\n",
    "\t\t\tdata_id = int(sent[2])\n",
    "\t\t\tpub_id = int(sent[3])\n",
    "\n",
    "\t\t\tfirst = 0\n",
    "\t\t\tj = 0\n",
    "\t\t\tstring = ''\n",
    "\t\t\tno_mention = True\n",
    "\t\t\twhile j<len(preds[i]):\n",
    "\t\t\t\twhile j<len(preds[i]) and preds[i][j]== 0:\n",
    "\t\t\t\t\tj+=1\n",
    "\t\t\t\tif j<len(preds[i]) and preds[i][j] == 1:\n",
    "\t\t\t\t\tno_mention=False\n",
    "\t\t\t\t\tstart = j\n",
    "\t\t\t\t\twhile j+1<len(preds[i]) and preds[i][j+1]==1:\n",
    "\t\t\t\t\t\tj+=1\n",
    "\t\t\t\t\tend = j \n",
    "\t\t\t\t\tif first > 0:\n",
    "\t\t\t\t\t\tstring += \" | \"\n",
    "\t\t\t\t\tstring += (str(start)+' '+str(end)+' '+str(data_id)+' '+str(pub_id))\n",
    "\t\t\t\t\tj+=1\n",
    "\t\t\t\t\tfirst += 1\n",
    "\t\t\tif no_mention:\n",
    "\t\t\t\tfout.write(\"0 0 0 \"+str(pub_id)+'\\n')\n",
    "\t\t\telse:\n",
    "\t\t\t\tfout.write(string+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6839745984310796\n",
      "0.8752334703025775\n"
     ]
    }
   ],
   "source": [
    "print (discovery_exact_match('../../outputs/BiLSTM_CRF_preds', '../../data/test.txt'))\n",
    "print (discovery_partial_match('../../outputs/BiLSTM_CRF_preds', '../../data/test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12760/17811 words covered in glove\n",
      "Train on 24094 samples, validate on 3347 samples\n",
      "Epoch 1/10\n",
      "24094/24094 [==============================] - 21s 867us/step - loss: 5.8249 - acc: 0.1100 - val_loss: 4.9291 - val_acc: 0.1183\n",
      "Epoch 2/10\n",
      "24094/24094 [==============================] - 17s 693us/step - loss: 4.7587 - acc: 0.1151 - val_loss: 4.5548 - val_acc: 0.1183\n",
      "Epoch 3/10\n",
      "24094/24094 [==============================] - 17s 689us/step - loss: 4.4124 - acc: 0.1151 - val_loss: 4.3034 - val_acc: 0.1183\n",
      "2677/2677 [==============================] - 1s 320us/step\n",
      "CNN model test accuracy:  [4.345270836936657, 0.11206574525112174]\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Dropout, Dense, LSTM, Bidirectional, Input, Dense, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "def data_loader(file):\n",
    "\twith open(file, 'r') as f:\n",
    "\t\tsents = []\n",
    "\t\tlabels = []\n",
    "\t\tfor line in f:\n",
    "\t\t\tline = line.strip().split()\n",
    "\t\t\tlabels.append(int(line[2]))\n",
    "\t\t\tsents.append(' '.join(line[4:]))\n",
    "\treturn sents, labels\n",
    "\n",
    "\n",
    "train_sents, train_labels = data_loader(\"../../data/train.txt\")\n",
    "val_sents, val_labels = data_loader(\"../../data/validate.txt\")\n",
    "test_sents, test_labels = data_loader(\"../../data/test.txt\")\n",
    "\n",
    "\n",
    "data_set = pd.read_json('../../../train_test/data_sets.json', encoding='utf-8')\n",
    "# #note: dataset_id = index + 1\n",
    "data_description = data_set[\"description\"].values\n",
    "\n",
    "\n",
    "# Add a sentence for no mention case\n",
    "data_description = list(data_description)\n",
    "data_description.insert(0, \"There is no mention.\")\n",
    "\n",
    "\n",
    "maxlen = 30\n",
    "#vocab_size = 40000 ##more than 80K unique tokens\n",
    "emb_dim = 50\n",
    "HIDDEN_DIM = 256\n",
    "EPOCHS = 10  \n",
    "NEG_RATIO = 3\n",
    "BATCH_SIZE = 10\n",
    "DATASET_CLASS = len(data_description) \n",
    "MODEL_NAME = \"CNN\"\n",
    "\n",
    "#actual batch size = BATCH_SIZE * (1 + NEG_RATIO)\n",
    "\n",
    "##load glove\n",
    "# embedding_index = {}\n",
    "# f = open('../glove.6B.50d.txt')\n",
    "# for line in f:\n",
    "# \tvalues = line.split()\n",
    "# \tword = values[0]\n",
    "# \tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "# \tembedding_index[word] = coefs\n",
    "# f.close()\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_sents+val_sents+test_sents)\n",
    "X_train = tokenizer.texts_to_sequences(train_sents)\n",
    "X_val = tokenizer.texts_to_sequences(val_sents)\n",
    "X_test = tokenizer.texts_to_sequences(test_sents)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "##hyperparameters\n",
    "vocab_size = len(word_index)+1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "counter = 0\n",
    "for word, i in word_index.items():\n",
    "\tembedding_vector = embedding_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "\t\tcounter += 1\n",
    "\telse:\n",
    "\t\tembedding_matrix[i] = np.random.randn(emb_dim)\n",
    "print (\"{}/{} words covered in glove\".format(counter, vocab_size))\n",
    "\n",
    "\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "Y_train = np.asarray(train_labels)\n",
    "Y_val = np.asarray(val_labels)\n",
    "Y_test = np.asarray(test_labels)\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=DATASET_CLASS)\n",
    "Y_val = keras.utils.to_categorical(Y_val, num_classes=DATASET_CLASS)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=DATASET_CLASS)\n",
    "\n",
    "\n",
    "##randomly shuffle data and labels\n",
    "##np.random.seed(0)\n",
    "N = X_train.shape[0]\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices] \n",
    "\n",
    "\n",
    "def build_model():\n",
    "\t#CNN model, 1D conv\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(layers.Embedding(vocab_size, emb_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "\tmodel.add(layers.Conv1D(64, 5, activation='relu'))\n",
    "\tmodel.add(layers.MaxPooling1D(3))\n",
    "\tmodel.add(layers.Conv1D(32, 4, activation='relu'))\n",
    "\tmodel.add(layers.GlobalMaxPooling1D())\n",
    "\tmodel.add(layers.Dense(DATASET_CLASS, activation=\"sigmoid\"))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model \n",
    "\n",
    "model = build_model()\n",
    "\n",
    "callbacks_list = [\n",
    "\tkeras.callbacks.EarlyStopping(\n",
    "\t\tmonitor='val_acc',\n",
    "\t\tpatience=2)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "\t\t\t\t\tepochs=EPOCHS,\n",
    "\t\t\t\t\tbatch_size=128,\n",
    "\t\t\t\t\tvalidation_data=(X_val, Y_val),\n",
    "\t\t\t\t\tcallbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n",
    "print ('CNN model test accuracy: ', model.evaluate(X_test, Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2677, 10349)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2_test = np.asarray([np.argmax(a) for a in Y_test])\n",
    "preds2 = np.asarray([np.argmax(a) for a in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.11206574523720583, 0.11206574523720583, 0.11206574523720583, None)\n",
      "(0.00018898102063609753, 0.0016863406408094434, 0.0003398738275061022, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sichenglei/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print (sklearn.metrics.precision_recall_fscore_support(Y2_test, preds2, average='micro'))\n",
    "print (sklearn.metrics.precision_recall_fscore_support(Y2_test, preds2, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12760/17811 words covered in glove\n",
      "Train on 24094 samples, validate on 3347 samples\n",
      "Epoch 1/10\n",
      "24094/24094 [==============================] - 125s 5ms/step - loss: 5.6160 - acc: 0.1044 - val_loss: 4.8284 - val_acc: 0.1183\n",
      "Epoch 2/10\n",
      "24094/24094 [==============================] - 114s 5ms/step - loss: 4.6441 - acc: 0.1150 - val_loss: 4.4153 - val_acc: 0.1183\n",
      "Epoch 3/10\n",
      "24094/24094 [==============================] - 118s 5ms/step - loss: 4.1616 - acc: 0.1202 - val_loss: 3.8129 - val_acc: 0.1365\n",
      "Epoch 4/10\n",
      "24094/24094 [==============================] - 115s 5ms/step - loss: 3.5787 - acc: 0.2073 - val_loss: 3.2048 - val_acc: 0.2689\n",
      "Epoch 5/10\n",
      "24094/24094 [==============================] - 132s 5ms/step - loss: 3.0829 - acc: 0.2773 - val_loss: 2.8075 - val_acc: 0.3209\n",
      "Epoch 6/10\n",
      "24094/24094 [==============================] - 135s 6ms/step - loss: 2.7288 - acc: 0.3259 - val_loss: 2.5817 - val_acc: 0.3448\n",
      "Epoch 7/10\n",
      "24094/24094 [==============================] - 133s 6ms/step - loss: 2.4907 - acc: 0.3468 - val_loss: 2.4280 - val_acc: 0.3567\n",
      "Epoch 8/10\n",
      "24094/24094 [==============================] - 122s 5ms/step - loss: 2.3013 - acc: 0.3635 - val_loss: 2.3150 - val_acc: 0.3582\n",
      "Epoch 9/10\n",
      "24094/24094 [==============================] - 121s 5ms/step - loss: 2.1565 - acc: 0.3844 - val_loss: 2.2259 - val_acc: 0.3803\n",
      "Epoch 10/10\n",
      "24094/24094 [==============================] - 127s 5ms/step - loss: 2.0489 - acc: 0.3969 - val_loss: 2.1575 - val_acc: 0.3824\n",
      "2677/2677 [==============================] - 5s 2ms/step\n",
      "BiLSTM test accuracy:  [2.1897606587828564, 0.37579379907886085]\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Dropout, Dense, LSTM, Bidirectional, Input, Dense, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "def data_loader(file):\n",
    "    with open(file, 'r') as f:\n",
    "        sents = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            labels.append(int(line[2]))\n",
    "            sents.append(' '.join(line[4:]))\n",
    "    return sents, labels\n",
    "\n",
    "\n",
    "train_sents, train_labels = data_loader(\"../../data/train.txt\")\n",
    "val_sents, val_labels = data_loader(\"../../data/validate.txt\")\n",
    "test_sents, test_labels = data_loader(\"../../data/test.txt\")\n",
    "\n",
    "\n",
    "data_set = pd.read_json('../../../train_test/data_sets.json', encoding='utf-8')\n",
    "#note: dataset_id = index + 1\n",
    "data_description = data_set[\"description\"].values\n",
    "\n",
    "\n",
    "# Add a sentence for no mention case\n",
    "data_description = list(data_description)\n",
    "data_description.insert(0, \"There is no mention.\")\n",
    "\n",
    "\n",
    "maxlen = 30\n",
    "#vocab_size = 40000 ##more than 80K unique tokens\n",
    "emb_dim = 50\n",
    "HIDDEN_DIM = 256\n",
    "EPOCHS = 10  ## train more epochs with GPU, it takes 1h per epoch on my CPU\n",
    "NEG_RATIO = 3\n",
    "BATCH_SIZE = 10\n",
    "DATASET_CLASS = len(data_description) \n",
    "MODEL_NAME = \"LSTM\"\n",
    "\n",
    "#actual batch size = BATCH_SIZE * (1 + NEG_RATIO)\n",
    "\n",
    "##load glove\n",
    "embedding_index = {}\n",
    "f = open('../glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "###NOT using dataset info anymore\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_sents+val_sents+test_sents)\n",
    "X_train = tokenizer.texts_to_sequences(train_sents)\n",
    "X_val = tokenizer.texts_to_sequences(val_sents)\n",
    "X_test = tokenizer.texts_to_sequences(test_sents)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)+1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "counter = 0\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        counter += 1\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.randn(emb_dim)\n",
    "print (\"{}/{} words covered in glove\".format(counter, vocab_size))\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "Y_train = np.asarray(train_labels)\n",
    "Y_val = np.asarray(val_labels)\n",
    "Y_test = np.asarray(test_labels)\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=DATASET_CLASS)\n",
    "Y_val = keras.utils.to_categorical(Y_val, num_classes=DATASET_CLASS)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=DATASET_CLASS)\n",
    "\n",
    "\n",
    "##randomly shuffle data and labels\n",
    "##np.random.seed(0)\n",
    "N = X_train.shape[0]\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "Y_train = Y_train[indices] \n",
    "\n",
    "\n",
    "def build_model():\n",
    "    embedding_layer = Embedding(vocab_size, emb_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "    article_input = Input(shape=(maxlen,), dtype='int32')\n",
    "    article_emb = embedding_layer(article_input)\n",
    "    \n",
    "    article_lstm = LSTM(HIDDEN_DIM, dropout=0.2, recurrent_dropout=0.3)\n",
    "    article_vector = article_lstm(article_emb)\n",
    "    #vector shape: (batch_size, hidden_dim)\n",
    "    \n",
    "    dense_vector = Dense(HIDDEN_DIM*4)(article_vector)\n",
    "    \n",
    "    dense_vector = Dropout(0.3)(dense_vector)\n",
    "    output = Dense(DATASET_CLASS, activation='sigmoid')(dense_vector)\n",
    "    \n",
    "    model = Model(article_input, output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "model = build_model()\n",
    "\n",
    "callbacks_list = [\n",
    "\tkeras.callbacks.EarlyStopping(\n",
    "\t\tmonitor='val_acc',\n",
    "\t\tpatience=2)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "print ('BiLSTM test accuracy: ', model.evaluate(X_test, Y_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.38924168845722823, 0.38924168845722823, 0.38924168845722823, None)\n",
      "(0.14152911254941078, 0.153139380196953, 0.13664545465552758, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sichenglei/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/sichenglei/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "Y2_test = np.asarray([np.argmax(a) for a in Y_test])\n",
    "preds2 = np.asarray([np.argmax(a) for a in preds])\n",
    "print (sklearn.metrics.precision_recall_fscore_support(Y2_test, preds2, average='micro'))\n",
    "print (sklearn.metrics.precision_recall_fscore_support(Y2_test, preds2, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
