{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from data_reader import *\n",
    "from evaluate_new import *\n",
    "from sklearn_crfsuite import CRF \n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "## Get the doc level test data\n",
    "doc_dir = \"../../../data_doc/\"\n",
    "def get_doc_test(labels=\"golden_data\", text=\"test_file\"):\n",
    "    test_labels = []\n",
    "    test_doc = []\n",
    "    with open(doc_dir+labels, 'r') as doc_labels, open(doc_dir+text, 'r') as doc_text:\n",
    "        d_labels = doc_labels.readlines()\n",
    "        d_text = doc_text.readlines()\n",
    "        assert len(d_labels) == len(d_text), \"Mismatch\"\n",
    "        for i in range(len(d_labels)):\n",
    "            test_labels.append(d_labels[i].strip())\n",
    "            \n",
    "            text = d_text[i].strip()\n",
    "            text = re.sub('\\d', '0', text)\n",
    "            text = re.sub('[^ ]- ', '', text)\n",
    "            \n",
    "            test_doc.append(text)\n",
    "    return test_labels, test_doc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_test_y, doc_test_x = get_doc_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert doc data to (text, label)\n",
    "def read_doc(doc, labels):\n",
    "    doc = doc.strip().split()\n",
    "    labels = labels.strip().split('|')\n",
    "    labels = [la.split() for la in labels]\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            labels[i][j] = int(labels[i][j])\n",
    "\n",
    "    res_labels = [0]*len(doc)\n",
    "    for la in labels:\n",
    "        if la[2]!=0:\n",
    "            start = la[0]\n",
    "            end = la[1]\n",
    "            res_labels[start : end+1] = [1]*(end+1-start)\n",
    "    return [(doc[i], str(res_labels[i])) for i in range(len(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tests = [read_doc(doc_test_x[d], doc_test_y[d]) for d in range(len(doc_test_x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict one doc\n",
    "def doc_pred(model, doc, MAXLEN):\n",
    "    splits = []\n",
    "    for i in range(0, len(doc), MAXLEN):\n",
    "        splits.append(doc[i : i+MAXLEN])\n",
    "    preds = model.predict(splits)\n",
    "    preds = [p for pd in preds for p in pd]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    ##youmay add more features\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "##CRF takes string as labels\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_dir, doc_out_dir, gold_dir):\n",
    "    train_sents = get_sents(train_dir)\n",
    "    # test_sents = get_sents(\"../../../data_30_0.1%neg/test.txt\")\n",
    "\n",
    "    ##labels are strings\n",
    "    X_train = [sent2features(s) for s in train_sents]\n",
    "    Y_train = [sent2labels(s) for s in train_sents]\n",
    "    # X_test = [sent2features(s) for s in test_sents]\n",
    "    # Y_test = [sent2labels(s) for s in test_sents]\n",
    "    X_doc_test = [sent2features(s) for s in doc_tests]\n",
    "\n",
    "    crf = CRF(algorithm='lbfgs',\n",
    "              c1=0.1,\n",
    "              c2=0.1,\n",
    "              max_iterations=100,\n",
    "              all_possible_transitions=False)\n",
    "\n",
    "    crf.fit(X_train, Y_train)\n",
    "    \n",
    "    doc_preds = [doc_pred(crf, d, 30) for d in X_doc_test]\n",
    "    doc_preds = [[int(a) for a in x] for x in doc_preds]\n",
    "    ## record the prediceted start and end index\n",
    "    ## for doc level\n",
    "    ## write all start and end indices (0 0 if not mention)\n",
    "    with open(doc_out_dir, 'w') as fout:\n",
    "        for i in range(len(doc_preds)):\n",
    "            first = 0\n",
    "            j = 0\n",
    "            string = ''\n",
    "            no_mention = True\n",
    "            while j<len(doc_preds[i]):\n",
    "                while j<len(doc_preds[i]) and doc_preds[i][j]== 0:\n",
    "                    j+=1\n",
    "                if j<len(doc_preds[i]) and doc_preds[i][j] == 1:\n",
    "                    no_mention=False\n",
    "                    start = j\n",
    "                    while j+1<len(doc_preds[i]) and doc_preds[i][j+1]==1:\n",
    "                        j+=1\n",
    "                    end = j \n",
    "                    if first > 0:\n",
    "                        string += \" | \"\n",
    "                    string += (str(start)+' '+str(end))\n",
    "                    j+=1\n",
    "                    first += 1\n",
    "            if no_mention:\n",
    "                fout.write(\"0 0\"'\\n')\n",
    "            else:\n",
    "                fout.write(string+'\\n')\n",
    "                \n",
    "    print ('doc exact: ', doc_exact_match(doc_out_dir, gold_dir))\n",
    "    print ('doc partial: ', doc_partial_match(doc_out_dir, gold_dir))\n",
    "#     print ('fragment exact: ', discovery_exact_match(doc_out_dir, gold_dir))\n",
    "#     print ('fragment exact: ', discovery_partial_match(doc_out_dir, gold_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026109660574412533\n",
      "0.004351610095735422\n",
      "0.0017528483786152498\n",
      "0.0017528483786152498\n"
     ]
    }
   ],
   "source": [
    "run(train_dir=\"../../../data_30_0.1%neg/train.txt\", doc_out_dir='../../../doc_outputs_30/CRF_0.1_preds', \n",
    "    gold_dir='../../../data_doc_30/golden_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc exact:  0.010291595197255575\n",
      "doc partial:  0.012006861063464836\n"
     ]
    }
   ],
   "source": [
    "run(train_dir=\"../../../data_30_1%neg/train.txt\", doc_out_dir='../../../doc_outputs_30/CRF_1_preds', \n",
    "    gold_dir='../../../data_doc_30/golden_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc exact:  0.08270676691729323\n",
      "doc partial:  0.08270676691729323\n"
     ]
    }
   ],
   "source": [
    "run(train_dir=\"../../../data_30_10%neg/train.txt\", doc_out_dir='../../../doc_outputs_30/CRF_10_preds', \n",
    "    gold_dir='../../../data_doc_30/golden_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
