{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sichenglei/Desktop/kaggle/salt/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "\n",
      "Bad key \"ckend\" on line 1 in\n",
      "/Users/sichenglei/.matplotlib/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "/Users/sichenglei/Desktop/kaggle/salt/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from data_reader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = get_sents(\"../../data/train.txt\")\n",
    "val_sents = get_sents(\"../../data/validate.txt\")\n",
    "test_sents = get_sents(\"../../data/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF (F1: 0.967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    ##you may add more features\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "Y_train = [sent2labels(s) for s in train_sents]\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "Y_test = [sent2labels(s) for s in test_sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=False, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import CRF \n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "crf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9667331846190463"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(Y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.978     0.991     0.984    323645\n",
      "          1      0.618     0.402     0.487     11955\n",
      "\n",
      "avg / total      0.965     0.970     0.967    335600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    Y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM (F1: 0.978)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [int(label) for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2tokens(s) for s in train_sents]\n",
    "Y_train = [sent2labels(s) for s in train_sents]\n",
    "X_val = [sent2tokens(s) for s in val_sents]\n",
    "Y_val = [sent2labels(s) for s in val_sents]\n",
    "X_test = [sent2tokens(s) for s in test_sents]\n",
    "Y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46495\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_val = np.asarray(Y_val)\n",
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels need to be 3D\n",
    "Y_train = np.expand_dims(Y_train, axis=2)\n",
    "Y_val = np.expand_dims(Y_val, axis=2)\n",
    "Y_test = np.expand_dims(Y_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "\n",
    "emb_dim = 50\n",
    "input = Input(shape=(maxlen,))\n",
    "model = Embedding(vocab_size, emb_dim, input_length=maxlen)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(1, activation='sigmoid'))(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 100, 50)           2324800   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 100, 200)          120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 100, 1)            201       \n",
      "=================================================================\n",
      "Total params: 2,445,801\n",
      "Trainable params: 2,445,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30208 samples, validate on 4196 samples\n",
      "Epoch 1/5\n",
      "30208/30208 [==============================] - 219s 7ms/step - loss: 0.1052 - acc: 0.9665 - val_loss: 0.0663 - val_acc: 0.9715\n",
      "Epoch 2/5\n",
      "30208/30208 [==============================] - 199s 7ms/step - loss: 0.0565 - acc: 0.9752 - val_loss: 0.0565 - val_acc: 0.9757\n",
      "Epoch 3/5\n",
      "30208/30208 [==============================] - 211s 7ms/step - loss: 0.0481 - acc: 0.9786 - val_loss: 0.0529 - val_acc: 0.9770\n",
      "Epoch 4/5\n",
      "30208/30208 [==============================] - 206s 7ms/step - loss: 0.0429 - acc: 0.9808 - val_loss: 0.0535 - val_acc: 0.9766\n",
      "Epoch 5/5\n",
      "30208/30208 [==============================] - 212s 7ms/step - loss: 0.0395 - acc: 0.9822 - val_loss: 0.0490 - val_acc: 0.9785\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=64, epochs=5, validation_data=(X_val, Y_val)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [[1 if y>=0.5 else 0 for y in x] for x in preds]\n",
    "test = np.reshape(np.asarray(test), (-1))\n",
    "target = np.reshape(Y_test, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.98940991, 0.69476342]),\n",
       " array([0.98841941, 0.71359264]),\n",
       " array([0.98891441, 0.70405216]),\n",
       " array([323645,  11955]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(target, test, average=None,\n",
    "                                              labels=[0, 1])\n",
    "#output shape:\n",
    "#precision \n",
    "#recall\n",
    "#fscore\n",
    "#support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9786293206197855, 0.9786293206197855, 0.9786293206197855, None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(target, test, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-CRF (F1: 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional  \n",
    "from keras_contrib.layers import CRF\n",
    "import keras\n",
    "\n",
    "##using the same processed datasets from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen,))\n",
    "model = Embedding(vocab_size, emb_dim, input_length=maxlen)(input)\n",
    "model = Bidirectional(LSTM(50, return_sequences=True, recurrent_dropout=0.1))(model)    \n",
    "model = TimeDistributed(Dense(50, activation='relu'))(model)\n",
    "##use CRF instead of Dense\n",
    "crf = CRF(2)\n",
    "out = crf(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 100, 50)           2324800   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 100, 100)          40400     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 100, 50)           5050      \n",
      "_________________________________________________________________\n",
      "crf_2 (CRF)                  (None, 100, 2)            110       \n",
      "=================================================================\n",
      "Total params: 2,370,360\n",
      "Trainable params: 2,370,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_2 = keras.utils.to_categorical(Y_train)\n",
    "Y_val_2 = keras.utils.to_categorical(Y_val)\n",
    "Y_test_2 = keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=crf.loss_function, metrics=[crf.accuracy]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30208 samples, validate on 4196 samples\n",
      "Epoch 1/5\n",
      "30208/30208 [==============================] - 208s 7ms/step - loss: 0.0734 - acc: 0.9711 - val_loss: 0.0556 - val_acc: 0.9757\n",
      "Epoch 2/5\n",
      "30208/30208 [==============================] - 218s 7ms/step - loss: 0.0461 - acc: 0.9782 - val_loss: 0.0446 - val_acc: 0.9785\n",
      "Epoch 3/5\n",
      "30208/30208 [==============================] - 155s 5ms/step - loss: 0.0355 - acc: 0.9814 - val_loss: 0.0383 - val_acc: 0.9793\n",
      "Epoch 4/5\n",
      "30208/30208 [==============================] - 157s 5ms/step - loss: 0.0279 - acc: 0.9830 - val_loss: 0.0327 - val_acc: 0.9790\n",
      "Epoch 5/5\n",
      "30208/30208 [==============================] - 147s 5ms/step - loss: 0.0213 - acc: 0.9842 - val_loss: 0.0270 - val_acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train_2, batch_size=64, epochs=5, \n",
    "                   validation_data=(X_val, Y_val_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_labels = [np.argmax(d) for sent in preds for d in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335600"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99077792, 0.71402434]),\n",
       " array([0.98889215, 0.75081556]),\n",
       " array([0.98983414, 0.73195792]),\n",
       " array([323645,  11955]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(np.reshape(Y_test,(-1)), \n",
    "                                        preds_labels, \n",
    "                                        average=None,\n",
    "                                        labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9804112038140643, 0.9804112038140643, 0.9804112038140643, None)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(np.reshape(Y_test,(-1)), \n",
    "                                        preds_labels, \n",
    "                                        average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
