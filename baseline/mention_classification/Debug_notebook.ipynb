{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Dense, LSTM, Bidirectional, Input, Dense, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27149 sampled loaded\n"
     ]
    }
   ],
   "source": [
    "data_set = pd.read_json('../../train_test/data_sets.json', encoding='utf-8')\n",
    "#note: dataset_id = index + 1\n",
    "data_description = data_set[\"description\"].values\n",
    "\n",
    "DIR = '../../data/golden_data'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "with open(DIR, 'r') as f:\n",
    "\tfor line in f:\n",
    "\t\tline = line.strip().split()\n",
    "\t\tY.append(int(line[0]))\n",
    "\t\tX.append(' '.join(line[1:]))\n",
    "\n",
    "print (len(X), 'sampled loaded')\n",
    "\n",
    "##X: strings of texts\n",
    "##Y: dataset id mentioned in that string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a sentence for no mention case\n",
    "data_description = list(data_description)\n",
    "data_description.insert(0, \"There is no mention.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of adding a sentence for no mention, we can also train embedding vectors as a whole without uisng LSTM to run over the data description. But I think the data description provides some information and should have better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10349"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "vocab_size = 50000 ##more than 80K unique tokens\n",
    "EMB_DIM = 50\n",
    "HIDDEN_DIM = 256\n",
    "EPOCHS = 5  ## train more epochs with GPU, it takes 1h per epoch on my CPU\n",
    "NEG_RATIO = 3\n",
    "BATCH_SIZE = 10\n",
    "DATASET_CLASS = len(data_description) \n",
    "MODEL_NAME = \"LSTM\"\n",
    "\n",
    "#actual batch size = BATCH_SIZE * (1 + NEG_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81656 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X+data_description)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "des_seq = tokenizer.texts_to_sequences(list(data_description))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print (\"Found %s unique tokens.\"%len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(X_seq, maxlen=maxlen)\n",
    "des = pad_sequences(des_seq, maxlen=maxlen)\n",
    "labels = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##randomly shuffle data and labels\n",
    "##np.random.seed(0)\n",
    "N = data.shape[0]\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: if you want to reproduce the exact same result, you need to use the same dataset and the same random seed as mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I set apart the last 2000 samples as test set\n",
    "## 400 samples as validation\n",
    "val_data = data[-1200 : -1000]\n",
    "val_labels = labels[-1200 : -1000]\n",
    "test_data = data[-1000 : ]\n",
    "test_labels = labels[-1000 : ]\n",
    "data = data[ : -1200]\n",
    "labels = labels[ : -1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I am not using Glove here, may get better results with Glove\n",
    "def build_model():\n",
    "    embedding_layer = Embedding(vocab_size, EMB_DIM, input_length=maxlen)\n",
    "    article_input = Input(shape=(maxlen,), dtype='int32')\n",
    "    article_emb = embedding_layer(article_input)\n",
    "    \n",
    "    dataset_input = Input(shape=(maxlen,), dtype='int32')\n",
    "    dataset_emb = embedding_layer(dataset_input)\n",
    "    \n",
    "    article_lstm = LSTM(HIDDEN_DIM, dropout=0.2, recurrent_dropout=0.3)\n",
    "    article_vector = article_lstm(article_emb)\n",
    "    #vector shape: (batch_size, hidden_dim)\n",
    "    \n",
    "    dataset_lstm = LSTM(HIDDEN_DIM, dropout=0.2, recurrent_dropout=0.2)\n",
    "    dataset_vector = dataset_lstm(dataset_emb)\n",
    "    \n",
    "    merged = layers.merge.dot([article_vector, dataset_vector], axes=1)\n",
    "    #shape: (batch_size, 1)\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "    \n",
    "    model = Model([article_input, dataset_input], output)\n",
    "#     dataset_lstm_model = Model(dataset_input, dataset_vector)\n",
    "#     dataset_compare_model = Model([article_input, dataset_vector], output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model, dataset_lstm_model, dataset_compare_model\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the batch for each x_sample contains one correct match,\n",
    "##NEG_RATIO wrong matches, (negative sampling)\n",
    "##the batch_size here means how many different x_samples in one batch\n",
    "def generate_batch(x_samples, y_samples, datasets, batch_size, neg_ratio=3):\n",
    "    total_size = batch_size*(1+NEG_RATIO)\n",
    "    num_batches = len(x_samples) // batch_size\n",
    "    while True:\n",
    "        for batchIdx in range(0, num_batches):\n",
    "            start = batchIdx * batch_size\n",
    "            end = (batchIdx + 1) * batch_size\n",
    "            article_batch = np.zeros(shape=(total_size, maxlen))\n",
    "            dataset_batch = np.zeros(shape=(total_size, maxlen))\n",
    "            outputs = np.zeros(shape=(total_size,))\n",
    "            lineIdx = 0 ##index in the batch \n",
    "            \n",
    "            ## fill in one batch\n",
    "            for line in range(start, end):\n",
    "                #each x is used (1+neg_ratio) times\n",
    "                for i in range(1+NEG_RATIO):\n",
    "                    if i == 0:\n",
    "                        ## Add one correct match\n",
    "                        article_batch[lineIdx] = x_samples[line]\n",
    "                        dataset_idx = y_samples[line]\n",
    "                        dataset_batch[lineIdx] = datasets[dataset_idx]\n",
    "                        outputs[lineIdx] = 1\n",
    "                        lineIdx += 1\n",
    "                    else:\n",
    "                        dataset_idx = np.random.randint(0, DATASET_CLASS)\n",
    "                        while dataset_idx == y_samples[line]:\n",
    "                            dataset_idx = np.random.randint(0, DATASET_CLASS)\n",
    "                        article_batch[lineIdx] = x_samples[line]\n",
    "                        dataset_batch[lineIdx] = datasets[dataset_idx]\n",
    "                        outputs[lineIdx] = 0\n",
    "                        lineIdx += 1\n",
    "            \n",
    "            ##can shuffle the batch here as well\n",
    "            yield [article_batch, dataset_batch], outputs\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model, weight_file_path):\n",
    "    if os.path.exists(weight_file_path):\n",
    "        model.load_weights(weight_file_path)\n",
    "\n",
    "def get_weight_path(model_dir_path):\n",
    "    if not os.path.exists(model_dir_path):\n",
    "        os.makedirs(model_dir_path)\n",
    "    return model_dir_path + '/' + MODEL_NAME + '-weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##maybe the ratio I used is a bit big\n",
    "def fit(model, epochs=EPOCHS, batch_size=BATCH_SIZE, neg_ratio=NEG_RATIO, model_dir_path=None):  \n",
    "    if model_dir_path is None:\n",
    "        model_dir_path = '../../models'\n",
    "    weight_file_path = get_weight_path(model_dir_path)\n",
    "    checkpoint = ModelCheckpoint(weight_file_path, save_best_only=True)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "    train_gen = generate_batch(data, labels, des, batch_size, neg_ratio)\n",
    "    val_gen = generate_batch(val_data, val_labels, des, batch_size, neg_ratio)\n",
    "    train_num_batches = len(data) // batch_size\n",
    "    val_num_batches = len(val_data) // batch_size\n",
    "    history = model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
    "                                  epochs=epochs, verbose=1, callbacks=[checkpoint, earlystopping],\n",
    "                                  validation_data=val_gen, validation_steps=val_num_batches)\n",
    "    model.save_weights(weight_file_path)\n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the predicted mention and the confidence\n",
    "#label 0 means no mention\n",
    "def inference(test_data, datasets):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for x in test_data:\n",
    "        max_score = 0\n",
    "        max_index = 0\n",
    "        for i in tqdm(range(len(datasets))):\n",
    "            ##batch_size here is 1\n",
    "            s = model.predict([[x], [data[i]]])\n",
    "            if s > max_score:\n",
    "                max_score = s\n",
    "                max_index = i\n",
    "        scores.append(max_score)\n",
    "        labels.append(max_index)\n",
    "    return scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get all dataset vectors\n",
    "def get_dataset_vectors(dataset_lstm_model, datasets):\n",
    "    vectors = []\n",
    "    for data in datasets:\n",
    "        vectors.append(dataset_lstm_model.predict(dataset))\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_inference(dataset_compare_model, test_data, data_vectors):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    for data in test_data:\n",
    "        max_score = 0\n",
    "        max_index = 0\n",
    "        for i in range(len(datasets)):\n",
    "            s = dataset_compare_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(outputs, targets):\n",
    "    precision, recall, fscore, support = score(targets, output)\n",
    "    \n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('fscore: {}'.format(fscore))\n",
    "\n",
    "    return precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10349 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 2/10349 [00:00<10:42, 16.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 4/10349 [00:00<10:08, 17.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 6/10349 [00:00<09:42, 17.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 9/10349 [00:00<08:57, 19.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 12/10349 [00:00<08:26, 20.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 14/10349 [00:00<08:39, 19.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 16/10349 [00:00<10:14, 16.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 18/10349 [00:01<10:50, 15.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 20/10349 [00:01<10:43, 16.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 22/10349 [00:01<10:56, 15.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 24/10349 [00:01<10:45, 15.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 27/10349 [00:01<10:27, 16.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 29/10349 [00:01<10:34, 16.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 31/10349 [00:01<10:37, 16.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 34/10349 [00:02<10:20, 16.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 36/10349 [00:02<10:17, 16.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 38/10349 [00:02<10:13, 16.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 40/10349 [00:02<10:10, 16.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 42/10349 [00:02<10:31, 16.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 44/10349 [00:02<10:33, 16.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 46/10349 [00:02<10:38, 16.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 48/10349 [00:02<10:34, 16.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 50/10349 [00:03<10:30, 16.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 53/10349 [00:03<10:20, 16.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 55/10349 [00:03<10:38, 16.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 57/10349 [00:03<10:43, 16.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 59/10349 [00:03<10:39, 16.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 61/10349 [00:03<10:38, 16.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 63/10349 [00:04<10:54, 15.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 65/10349 [00:04<10:55, 15.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 67/10349 [00:04<10:54, 15.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 69/10349 [00:04<10:57, 15.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 71/10349 [00:04<10:57, 15.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 73/10349 [00:04<10:58, 15.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 75/10349 [00:04<10:58, 15.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 77/10349 [00:04<10:55, 15.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 79/10349 [00:05<10:53, 15.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 81/10349 [00:05<10:52, 15.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 84/10349 [00:05<10:45, 15.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 87/10349 [00:05<10:38, 16.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 90/10349 [00:05<10:31, 16.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 93/10349 [00:05<10:25, 16.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 96/10349 [00:05<10:20, 16.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 99/10349 [00:05<10:15, 16.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 102/10349 [00:06<10:13, 16.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 105/10349 [00:06<10:08, 16.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 108/10349 [00:06<10:04, 16.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 111/10349 [00:06<10:02, 17.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 114/10349 [00:06<09:58, 17.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 117/10349 [00:06<09:56, 17.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 120/10349 [00:06<09:52, 17.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 123/10349 [00:07<09:57, 17.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 125/10349 [00:07<09:57, 17.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 128/10349 [00:07<09:53, 17.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 130/10349 [00:07<09:53, 17.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 132/10349 [00:07<09:52, 17.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 134/10349 [00:07<09:51, 17.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 137/10349 [00:07<09:48, 17.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 140/10349 [00:08<09:47, 17.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 142/10349 [00:08<09:48, 17.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 144/10349 [00:08<09:48, 17.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 146/10349 [00:08<09:48, 17.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 148/10349 [00:08<09:47, 17.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 150/10349 [00:08<09:47, 17.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 152/10349 [00:08<09:46, 17.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 155/10349 [00:08<09:43, 17.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 158/10349 [00:09<09:41, 17.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 161/10349 [00:09<09:38, 17.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 164/10349 [00:09<09:35, 17.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 167/10349 [00:09<09:33, 17.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 170/10349 [00:09<09:31, 17.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 173/10349 [00:09<09:29, 17.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 176/10349 [00:09<09:26, 17.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 179/10349 [00:09<09:26, 17.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 182/10349 [00:10<09:23, 18.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 185/10349 [00:10<09:21, 18.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 188/10349 [00:10<09:21, 18.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 191/10349 [00:10<09:20, 18.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 194/10349 [00:10<09:18, 18.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 197/10349 [00:10<09:16, 18.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 200/10349 [00:10<09:15, 18.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 203/10349 [00:11<09:16, 18.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 205/10349 [00:11<09:16, 18.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 207/10349 [00:11<09:16, 18.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 209/10349 [00:11<09:17, 18.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 211/10349 [00:11<09:17, 18.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 213/10349 [00:11<09:19, 18.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 215/10349 [00:11<09:22, 18.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 217/10349 [00:12<09:23, 17.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 219/10349 [00:12<09:26, 17.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 221/10349 [00:12<09:32, 17.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 223/10349 [00:12<09:33, 17.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 225/10349 [00:12<09:34, 17.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 227/10349 [00:12<09:36, 17.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 229/10349 [00:13<09:35, 17.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 231/10349 [00:13<09:35, 17.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 233/10349 [00:13<09:36, 17.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 235/10349 [00:13<09:40, 17.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 237/10349 [00:13<09:42, 17.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 239/10349 [00:13<09:44, 17.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 241/10349 [00:13<09:46, 17.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 243/10349 [00:14<09:46, 17.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 245/10349 [00:14<09:46, 17.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 247/10349 [00:14<09:50, 17.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 249/10349 [00:14<09:53, 17.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 251/10349 [00:14<09:56, 16.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 253/10349 [00:14<09:55, 16.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 255/10349 [00:15<09:55, 16.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 257/10349 [00:15<09:56, 16.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 259/10349 [00:15<09:59, 16.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 261/10349 [00:15<10:00, 16.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 264/10349 [00:15<09:58, 16.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 266/10349 [00:15<09:57, 16.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 268/10349 [00:15<09:59, 16.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 270/10349 [00:16<09:59, 16.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 272/10349 [00:16<10:00, 16.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 274/10349 [00:16<10:00, 16.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 276/10349 [00:16<09:59, 16.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 278/10349 [00:16<10:00, 16.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 280/10349 [00:16<10:01, 16.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 282/10349 [00:16<10:02, 16.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 285/10349 [00:17<10:00, 16.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 288/10349 [00:17<10:00, 16.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 290/10349 [00:17<10:02, 16.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 292/10349 [00:17<10:02, 16.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 294/10349 [00:17<10:01, 16.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 297/10349 [00:17<09:59, 16.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 300/10349 [00:17<09:58, 16.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 303/10349 [00:18<09:58, 16.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 305/10349 [00:18<09:59, 16.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 307/10349 [00:18<10:00, 16.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 309/10349 [00:18<09:59, 16.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 312/10349 [00:18<09:58, 16.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 314/10349 [00:18<09:57, 16.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 317/10349 [00:18<09:55, 16.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 320/10349 [00:18<09:54, 16.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 323/10349 [00:19<09:53, 16.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 326/10349 [00:19<09:51, 16.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 329/10349 [00:19<09:50, 16.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 332/10349 [00:19<09:48, 17.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 335/10349 [00:19<09:47, 17.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 338/10349 [00:19<09:47, 17.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 341/10349 [00:19<09:46, 17.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 344/10349 [00:20<09:44, 17.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 347/10349 [00:20<09:43, 17.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 350/10349 [00:20<09:42, 17.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 353/10349 [00:20<09:40, 17.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 356/10349 [00:20<09:39, 17.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 359/10349 [00:20<09:38, 17.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 362/10349 [00:20<09:37, 17.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 365/10349 [00:21<09:36, 17.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 368/10349 [00:21<09:35, 17.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 371/10349 [00:21<09:34, 17.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 374/10349 [00:21<09:33, 17.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 377/10349 [00:21<09:32, 17.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 380/10349 [00:21<09:31, 17.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 383/10349 [00:21<09:30, 17.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 386/10349 [00:22<09:28, 17.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 389/10349 [00:22<09:27, 17.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 392/10349 [00:22<09:26, 17.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 395/10349 [00:22<09:24, 17.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 398/10349 [00:22<09:23, 17.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 401/10349 [00:22<09:22, 17.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 404/10349 [00:22<09:21, 17.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 407/10349 [00:22<09:20, 17.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 410/10349 [00:23<09:19, 17.78it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9a5d3980e4ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## The prediction is very slow because it computes dot product for every dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## it tales 7mins for one prediction, so i have to run it on GPU to evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-2e96defbaf13>\u001b[0m in \u001b[0;36minference\u001b[0;34m(test_data, datasets)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m##batch_size here is 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/salt/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 410/10349 [00:38<15:40, 10.57it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#model.load_weights(get_weight_path('../../models'))\n",
    "## The prediction is very slow because it computes dot product for every dataset\n",
    "## it tales 10mins for one prediction, so i have to run it on GPU to evaluate\n",
    "scores, output_labels = inference(test_data, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(output_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
